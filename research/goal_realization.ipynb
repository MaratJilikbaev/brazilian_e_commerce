{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to check last black friday sale and understand\n",
    "1) Our marketing department wants to know what product category purchase rate is the highest and also what product category is giving our company the highest amount of income.\n",
    "2) Is there price difference between black friday sales and other days sales? We want to increese our income so our company will try to decrease sale % (A/B test required)\n",
    "3) What categories of products were sold the most by state and city - we need to be sure that we have enough goods for our customers\n",
    "\n",
    "Having this 3 objectives here is the list of steps that we need to do\n",
    "1) import all related datasets\n",
    "2) check all the types of imported columns\n",
    "3) check all the columns for missing values\n",
    "4) check for anomalies\n",
    "5) rename-translate-transform data, create one big table, prepare it for analysis\n",
    "6) answer the questions\n",
    "\n",
    "Step 6 will be discussed later in details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all related datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need 4 tables here\n",
    "1) data/olist_orders_dataset.csv - here we have order_id, order_status and order_purchase_timestamp\n",
    "2) data/olist_order_items_dataset.csv - here we have order_id, product_id and price per item\n",
    "3) data/olist_products_dataset.csv - here we have product_id and product_category_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olist_orders_dataset.csv imported sucsessfully! Shape is (99441, 3)\n",
      "olist_order_items_dataset.csv imported sucsessfully! Shape is (112650, 3)\n",
      "olist_products_dataset.csv imported sucsessfully! Shape is (32951, 2)\n"
     ]
    }
   ],
   "source": [
    "orders_file_path = '../data/olist_orders_dataset.csv'\n",
    "order_items_file_path = '../data/olist_order_items_dataset.csv'\n",
    "products_file_path = '../data/olist_products_dataset.csv'\n",
    "\n",
    "orders_col_list = ['order_id', 'order_status', 'order_purchase_timestamp']\n",
    "order_items_col_list = ['order_id', 'product_id', 'price']\n",
    "products_col_list = ['product_id', 'product_category_name']\n",
    "\n",
    "# TODO prints will be logs in .py programm\n",
    "def get_filename_from_filepath(filepath):\n",
    "    # TODO add another checks - windows \\ path, case when file in the same dir, etc.\n",
    "    position_of_last_slash = filepath.rfind('/')\n",
    "    filename = filepath[position_of_last_slash + 1:]\n",
    "    return filename\n",
    "\n",
    "def import_and_check_dataframe(filepath: str, col_list):\n",
    "    # TODO add different imports for different filetypes\n",
    "    filename = get_filename_from_filepath(filepath)\n",
    "    # TODO add try exept here\n",
    "    df = pd.read_csv(filepath, usecols=col_list)\n",
    "\n",
    "    if ~df.empty:\n",
    "        print(filename + ' imported sucsessfully! Shape is', df.shape)\n",
    "    else:\n",
    "        print('Empty dataframe! Check file')\n",
    "\n",
    "    return df\n",
    "\n",
    "df_orders = import_and_check_dataframe(orders_file_path, orders_col_list)\n",
    "df_order_items = import_and_check_dataframe(order_items_file_path, order_items_col_list)\n",
    "df_products = import_and_check_dataframe(products_file_path, products_col_list)\n",
    "\n",
    "all_dataframes_with_names = [['orders_dataset', df_orders], ['order_items', df_order_items], ['products',df_products]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all the types of imported columns\n",
    "# Plus missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "general information on orders_dataset df\n",
      "----------------------------------------\n",
      "non missing values and dtypes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 3 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   order_id                  99441 non-null  object\n",
      " 1   order_status              99441 non-null  object\n",
      " 2   order_purchase_timestamp  99441 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "----------------------------------------\n",
      "only missing values\n",
      "order_id                    0\n",
      "order_status                0\n",
      "order_purchase_timestamp    0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "general information on order_items df\n",
      "----------------------------------------\n",
      "non missing values and dtypes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   order_id    112650 non-null  object \n",
      " 1   product_id  112650 non-null  object \n",
      " 2   price       112650 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "----------------------------------------\n",
      "only missing values\n",
      "order_id      0\n",
      "product_id    0\n",
      "price         0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "general information on products df\n",
      "----------------------------------------\n",
      "non missing values and dtypes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 2 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   product_id             32951 non-null  object\n",
      " 1   product_category_name  32341 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.0+ KB\n",
      "None\n",
      "----------------------------------------\n",
      "only missing values\n",
      "product_id                 0\n",
      "product_category_name    610\n",
      "dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def show_info_on_df(name_df_pair):\n",
    "    name = name_df_pair[0]\n",
    "    df = name_df_pair[1]\n",
    "    print('-' * 40)\n",
    "    print('general information on', name, 'df')\n",
    "    print('-' * 40)\n",
    "    print('non missing values and dtypes')\n",
    "    print(df.info())\n",
    "    print('-' * 40)\n",
    "    print('only missing values')\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    print('-' * 40)\n",
    "\n",
    "\n",
    "for pair in all_dataframes_with_names:\n",
    "    show_info_on_df(pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "order_purchase_timestamp column in df_orders imported as object. We need to transform it to datetime format\n",
    "\n",
    "We have 610 products with missing category. This is less than 2% of all products.<br>\n",
    "In most cases it is reasonable to drop this data, but let's be extra safe here and be sure that this products sell rate is low (we will check it later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 3 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   order_id                  99441 non-null  object        \n",
      " 1   order_status              99441 non-null  object        \n",
      " 2   order_purchase_timestamp  99441 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "2017-10-02 10:56:33 \n",
      "year\t 2017 \n",
      "month\t 10 \n",
      "day\t 2 \n",
      "hour\t 10\n",
      "everything is ok\n"
     ]
    }
   ],
   "source": [
    "# TODO we can create a function here. But for now it is only one column\n",
    "# TODO add possible format scheme for parsing timestamp like \"dd-mm-yyy HH:MM:SS\"\n",
    "# transform order_purchase_timestamp to datetime\n",
    "df_orders['order_purchase_timestamp'] = pd.to_datetime(df_orders['order_purchase_timestamp'])\n",
    "print(df_orders.info())\n",
    "print('-' * 80)\n",
    "\n",
    "# testing that everything worked just fine\n",
    "timestamp_test_obj = df_orders['order_purchase_timestamp'].iloc[0]\n",
    "\n",
    "try:\n",
    "    print(timestamp_test_obj, \n",
    "        \"\\nyear\\t\", timestamp_test_obj.year, \n",
    "        \"\\nmonth\\t\", timestamp_test_obj.month, \n",
    "        \"\\nday\\t\", timestamp_test_obj.day, \n",
    "        \"\\nhour\\t\", timestamp_test_obj.hour)\n",
    "    print('everything is ok')\n",
    "except Exception as e:\n",
    "    print(f'something is wrong, check error: \\n{e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "general stat information on orders_dataset df\n",
      "----------------------------------------\n",
      "                                order_id order_status order_purchase_timestamp\n",
      "count                              99441        99441                    99441\n",
      "unique                             99441            8                    98875\n",
      "top     e481f51cbdc54678b7cc49136f2d6af7    delivered      2018-04-11 10:48:14\n",
      "freq                                   1        96478                        3\n",
      "first                                NaN          NaN      2016-09-04 21:15:19\n",
      "last                                 NaN          NaN      2018-10-17 17:30:18\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "general stat information on order_items df\n",
      "----------------------------------------\n",
      "               price\n",
      "count  112650.000000\n",
      "mean      120.653739\n",
      "std       183.633928\n",
      "min         0.850000\n",
      "25%        39.900000\n",
      "50%        74.990000\n",
      "75%       134.900000\n",
      "max      6735.000000\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "general stat information on products df\n",
      "----------------------------------------\n",
      "                              product_id product_category_name\n",
      "count                              32951                 32341\n",
      "unique                             32951                    73\n",
      "top     1e9e8ef04dbcff4541ed26657ea517e5       cama_mesa_banho\n",
      "freq                                   1                  3029\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_375/670927774.py:7: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  print(df.describe())\n"
     ]
    }
   ],
   "source": [
    "def calculate_statistic_info(name_df_pair):\n",
    "    name = name_df_pair[0]\n",
    "    df = name_df_pair[1]\n",
    "    print('-' * 40)\n",
    "    print('general stat information on', name, 'df')\n",
    "    print('-' * 40)\n",
    "    print(df.describe())\n",
    "    print('-' * 40)\n",
    "\n",
    "\n",
    "for pair in all_dataframes_with_names:\n",
    "    calculate_statistic_info(pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like no anomalies here. Some prices could be really high and 6735$ for single item is something imaginable.\n",
    "Also we have data recorded for 2 years - so no 1900 year anomalies or something.\n",
    "Also it seems that logging of time is pretty precise because one of the most frequent value is 2018-04-11 10:48:14 and its only appears 3 times (and it is black friday) - so no delays or something in logging order_purchase_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create one big table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112650, 3)\n",
      "(112650, 6)\n",
      "----------------------------------------\n",
      "140136314151168\n",
      "140136318419056\n",
      "140136313836496\n",
      "140136923882736\n"
     ]
    }
   ],
   "source": [
    "# TODO here we can create function to check if our merges create duplicates - first thought: shape should remain the same\n",
    "\n",
    "print(df_order_items.shape)\n",
    "df_orders_plus = pd.merge(df_order_items, df_orders, on='order_id').merge(df_products, on='product_id')\n",
    "print(df_orders_plus.shape)\n",
    "\n",
    "# TODO remove this part, it is only for DEBUG and educational purposes\n",
    "# ------------------8<-----------------------\n",
    "# I'm just curious, let's check id's of this DataFrames objects. I bet df_orders_plus is in another memory cell\n",
    "print('-'*40)\n",
    "print(id(df_order_items))\n",
    "print(id(df_orders))\n",
    "print(id(df_products))\n",
    "print(id(df_orders_plus))\n",
    "\n",
    "# Nice =)\n",
    "# ------------------8<-----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's count how many products presented in db has no category 0.02 \n",
      "sum purch w/o category to all prch sum percent 1.32 \n",
      "count purch w/o category to all prch count percent 1.42\n"
     ]
    }
   ],
   "source": [
    "# Now we can check our products with missing categories\n",
    "sum_of_all_sold_products = df_orders_plus.price.sum()\n",
    "mask_for_purch_wo_category = df_orders_plus['product_category_name'].isnull()\n",
    "\n",
    "purch_wo_category_part_from_overall_purch_sum = df_orders_plus[mask_for_purch_wo_category].price.sum() / \\\n",
    "                                                sum_of_all_sold_products\n",
    "\n",
    "count_of_all_sold_products = df_orders_plus.shape[0]\n",
    "purch_wo_category_part_from_overall_purch_count = df_orders_plus[mask_for_purch_wo_category].shape[0] / \\\n",
    "                                                  count_of_all_sold_products\n",
    "\n",
    "print('let\\'s count how many products presented in db has no category',\n",
    "      np.float64(df_products.product_category_name.isnull().sum()/ df_products.shape[0]).round(2),\n",
    "      '\\nsum purch w/o category to all prch sum percent',     \n",
    "      (purch_wo_category_part_from_overall_purch_sum*100).round(2),\n",
    "      '\\ncount purch w/o category to all prch count percent',\n",
    "      np.float64(purch_wo_category_part_from_overall_purch_count*100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple analysis tels us that even there is only 0.02% of not products w/o category in our df_products dataset we can clearly see that sum and count of this products selling is more than 1%<br>\n",
    "We also don't have product names in our dataset. Only categories.<br>\n",
    "In real case scenario I would definitely consult with someone, who collected data or with business owner, but here I won't drop this data but I will assign \"unknown category\" label to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_plus['product_category_name'] = df_orders_plus['product_category_name'].fillna('unknown_category')\n",
    "# I have used underscore here. every category here is using this underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 112650 entries, 0 to 112649\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   order_id                  112650 non-null  object        \n",
      " 1   product_id                112650 non-null  object        \n",
      " 2   price                     112650 non-null  float64       \n",
      " 3   order_status              112650 non-null  object        \n",
      " 4   order_purchase_timestamp  112650 non-null  datetime64[ns]\n",
      " 5   product_category_name     112650 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orders_plus.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename-translate-transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cama_mesa_banho                  11115\n",
       "beleza_saude                      9670\n",
       "esporte_lazer                     8641\n",
       "moveis_decoracao                  8334\n",
       "informatica_acessorios            7827\n",
       "                                 ...  \n",
       "cds_dvds_musicais                   14\n",
       "la_cuisine                          14\n",
       "pc_gamer                             9\n",
       "fashion_roupa_infanto_juvenil        8\n",
       "seguros_e_servicos                   2\n",
       "Name: product_category_name, Length: 74, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_plus.product_category_name.value_counts()\n",
    "# categories are in foreign language and merged together, let's try to fix it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"languages\":[{\"language\":\"af\"},{\"language\":\"ak\"},{\"language\":\"am\"},{\"language\":\"ar\"},{\"language\":\"as\"},{\"language\":\"ay\"},{\"language\":\"az\"},{\"language\":\"be\"},{\"language\":\"bg\"},{\"language\":\"bho\"},{\"language\":\"bm\"},{\"language\":\"bn\"},{\"language\":\"bs\"},{\"language\":\"ca\"},{\"language\":\"ceb\"},{\"language\":\"ckb\"},{\"language\":\"co\"},{\"language\":\"cs\"},{\"language\":\"cy\"},{\"language\":\"da\"},{\"language\":\"de\"},{\"language\":\"doi\"},{\"language\":\"dv\"},{\"language\":\"ee\"},{\"language\":\"el\"},{\"language\":\"en\"},{\"language\":\"eo\"},{\"language\":\"es\"},{\"language\":\"et\"},{\"language\":\"eu\"},{\"language\":\"fa\"},{\"language\":\"fi\"},{\"language\":\"fr\"},{\"language\":\"fy\"},{\"language\":\"ga\"},{\"language\":\"gd\"},{\"language\":\"gl\"},{\"language\":\"gn\"},{\"language\":\"gom\"},{\"language\":\"gu\"},{\"language\":\"ha\"},{\"language\":\"haw\"},{\"language\":\"he\"},{\"language\":\"hi\"},{\"language\":\"hmn\"},{\"language\":\"hr\"},{\"language\":\"ht\"},{\"language\":\"hu\"},{\"language\":\"hy\"},{\"language\":\"id\"},{\"language\":\"ig\"},{\"language\":\"ilo\"},{\"language\":\"is\"},{\"language\":\"it\"},{\"language\":\"iw\"},{\"language\":\"ja\"},{\"language\":\"jw\"},{\"language\":\"ka\"},{\"language\":\"kk\"},{\"language\":\"km\"},{\"language\":\"kn\"},{\"language\":\"ko\"},{\"language\":\"kri\"},{\"language\":\"ku\"},{\"language\":\"ky\"},{\"language\":\"la\"},{\"language\":\"lb\"},{\"language\":\"lg\"},{\"language\":\"ln\"},{\"language\":\"lo\"},{\"language\":\"lt\"},{\"language\":\"lus\"},{\"language\":\"lv\"},{\"language\":\"mai\"},{\"language\":\"mg\"},{\"language\":\"mi\"},{\"language\":\"mk\"},{\"language\":\"ml\"},{\"language\":\"mn\"},{\"language\":\"mni-Mtei\"},{\"language\":\"mr\"},{\"language\":\"ms\"},{\"language\":\"mt\"},{\"language\":\"my\"},{\"language\":\"ne\"},{\"language\":\"nl\"},{\"language\":\"no\"},{\"language\":\"nso\"},{\"language\":\"ny\"},{\"language\":\"om\"},{\"language\":\"or\"},{\"language\":\"pa\"},{\"language\":\"pl\"},{\"language\":\"ps\"},{\"language\":\"pt\"},{\"language\":\"qu\"},{\"language\":\"ro\"},{\"language\":\"ru\"},{\"language\":\"rw\"},{\"language\":\"sa\"},{\"language\":\"sd\"},{\"language\":\"si\"},{\"language\":\"sk\"},{\"language\":\"sl\"},{\"language\":\"sm\"},{\"language\":\"sn\"},{\"language\":\"so\"},{\"language\":\"sq\"},{\"language\":\"sr\"},{\"language\":\"st\"},{\"language\":\"su\"},{\"language\":\"sv\"},{\"language\":\"sw\"},{\"language\":\"ta\"},{\"language\":\"te\"},{\"language\":\"tg\"},{\"language\":\"th\"},{\"language\":\"ti\"},{\"language\":\"tk\"},{\"language\":\"tl\"},{\"language\":\"tr\"},{\"language\":\"ts\"},{\"language\":\"tt\"},{\"language\":\"ug\"},{\"language\":\"uk\"},{\"language\":\"ur\"},{\"language\":\"uz\"},{\"language\":\"vi\"},{\"language\":\"xh\"},{\"language\":\"yi\"},{\"language\":\"yo\"},{\"language\":\"zh\"},{\"language\":\"zh-CN\"},{\"language\":\"zh-TW\"},{\"language\":\"zu\"}]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "url = \"https://google-translate1.p.rapidapi.com/language/translate/v2/languages\"\n",
    "\n",
    "headers = {\n",
    "\t\"Accept-Encoding\": \"application/gzip\",\n",
    "\t\"X-RapidAPI-Key\": \"951fd9ac96msh3b013ff9c3e72bap1e98f8jsnae389f244e8b\",\n",
    "\t\"X-RapidAPI-Host\": \"google-translate1.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"translations\":[{\"translatedText\":\"¡Hola Mundo!\"}]}}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://google-translate1.p.rapidapi.com/language/translate/v2\"\n",
    "\n",
    "payload = \"q=Hello%2C%20world!&target=es&source=en\"\n",
    "headers = {\n",
    "\t\"content-type\": \"application/x-www-form-urlencoded\",\n",
    "\t\"Accept-Encoding\": \"application/gzip\",\n",
    "\t\"X-RapidAPI-Key\": \"951fd9ac96msh3b013ff9c3e72bap1e98f8jsnae389f244e8b\",\n",
    "\t\"X-RapidAPI-Host\": \"google-translate1.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, we have this google translate API via rapidapi.com. We can do 5 requests per second and no more 500 requests per month. So, we have like 495 requests more to finish this translation<br>\n",
    "Last .value_counts() operation showed us, that we have only 74 unique categories, so we can try to create multiple dicts with translations for categories<br>\n",
    "Then we need to serialize this python object to have it in file for next usages (again, we have only 500 requests per month, 5 requests per second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q=moveis_decoracao&target=en&source=pt'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try our value\n",
    "def create_payload_from_value(value, target='en', source='pt'):\n",
    "    payload = \"q=\"\n",
    "    payload += value\n",
    "    payload += f'&target={target}&source={source}'\n",
    "    return payload\n",
    "\n",
    "create_payload_from_value(df_orders_plus.product_category_name.unique()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ferramentas_jardim'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_plus.product_category_name.unique()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"translations\":[{\"translatedText\":\"furniture_decoration\"}]}}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://google-translate1.p.rapidapi.com/language/translate/v2\"\n",
    "\n",
    "payload = create_payload_from_value(df_orders_plus.product_category_name.unique()[2])\n",
    "headers = {\n",
    "\t\"content-type\": \"application/x-www-form-urlencoded\",\n",
    "\t\"Accept-Encoding\": \"application/gzip\",\n",
    "\t\"X-RapidAPI-Key\": \"951fd9ac96msh3b013ff9c3e72bap1e98f8jsnae389f244e8b\",\n",
    "\t\"X-RapidAPI-Host\": \"google-translate1.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it worked. Let's try to create our first dict<br>\n",
    "but I will save it with \"if False:\" just to be sure that this part is not executing automaticly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_from_pt_to_en(str_to_translate):\n",
    "    url = \"https://google-translate1.p.rapidapi.com/language/translate/v2\"\n",
    "    headers = {\n",
    "\t\"content-type\": \"application/x-www-form-urlencoded\",\n",
    "\t\"Accept-Encoding\": \"application/gzip\",\n",
    "\t\"X-RapidAPI-Key\": \"951fd9ac96msh3b013ff9c3e72bap1e98f8jsnae389f244e8b\",\n",
    "\t\"X-RapidAPI-Host\": \"google-translate1.p.rapidapi.com\"\n",
    "    }\n",
    "    payload = create_payload_from_value(str_to_translate)\n",
    "    \n",
    "    responce = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "    parsed_translation = json.loads(responce.text)['data']['translations'][0]['translatedText']\n",
    "\n",
    "    return parsed_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = translate_from_pt_to_en('ferramentas_jardim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garden_tools\n",
      "garden_tools\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "time.sleep(0.21)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_series_of_values(series_of_values: pd.Series):\n",
    "    translation = {}\n",
    "    # used [:5] here just for debug perpuses\n",
    "    for element in series_of_values.unique()[:5]:\n",
    "        translation[element] = translate_from_pt_to_en(element)\n",
    "        # we need to sleep here because our max requests is 5 per second\n",
    "        time.sleep(0.21)\n",
    "    \n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cool_stuff', 'pet_shop', 'moveis_decoracao', 'perfumaria',\n",
       "       'ferramentas_jardim'], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_plus.product_category_name.unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(obj, file_name):\n",
    "\n",
    "    # Overwrites any existing file\n",
    "    with open(file_name, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def de_serialize(file_name):\n",
    "\n",
    "    with open(file_name, 'rb') as input:\n",
    "        obj = pickle.load(input)\n",
    "        return obj\n",
    "\n",
    "cached_path = 'data/cached/category_translate_dict.pkl'\n",
    "\n",
    "if os.path.isfile(cached_path):\n",
    "    data = de_serialize(cached_path)\n",
    "else:\n",
    "    data = {}\n",
    "    serialize(data, cached_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'translations': [{'translatedText': 'garden_tools'}]}}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b07d4539a9d93b727089c842ffadd80a5b39ca4601e10897dfedaa202771bfd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
